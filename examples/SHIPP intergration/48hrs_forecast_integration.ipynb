{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "48-Hour Day-Ahead Electricity Price Forecasting using LEAR Model\n",
    "\n",
    "This script performs a two-step 48-hour rolling forecast for electricity prices \n",
    "on the Nord Pool market using the LEAR model. It includes probabilistic post-processing \n",
    "and error metrics for each lead time.\n",
    "\n",
    "Dependencies\n",
    "------------\n",
    "- pandas\n",
    "- numpy\n",
    "- seaborn\n",
    "- matplotlib\n",
    "- epftoolbox (for LEAR model and data handling)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from epftoolbox.data import read_data\n",
    "from epftoolbox.evaluation import MAE, sMAPE\n",
    "from epftoolbox.models import LEAR\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# PARAMETERS AND DATA LOADING\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Dataset and model settings\n",
    "dataset = 'NP'  # Nord Pool region\n",
    "calibration_window = 364 * 2  # Two-year training window\n",
    "\n",
    "# Testing period for backtesting\n",
    "begin_test_date = \"01/01/2018 00:00\"\n",
    "end_test_date = \"31/03/2018 23:00\"\n",
    "\n",
    "# Paths for data and forecasts\n",
    "path_datasets_folder = os.path.join('.', 'datasets')\n",
    "path_recalibration_folder = os.path.join('.' , 'experimental_files')\n",
    "\n",
    "# Load pre-split train/test data from epftoolbox\n",
    "df_train, df_test = read_data(dataset=dataset,\n",
    "                              path=path_datasets_folder,\n",
    "                              begin_test_date=begin_test_date,\n",
    "                              end_test_date=end_test_date)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# REAL VALUE EXTRACTION FOR VERIFICATION\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Initialize placeholder for 48h rolling forecasts and real data\n",
    "forecast = pd.DataFrame(index=df_test.index[::24], columns=['h' + str(k) for k in range(48)])\n",
    "real_values = []\n",
    "forecast_index = []\n",
    "\n",
    "# Manually slice 48-hour real price windows every 24 hours\n",
    "for i in range(0, len(df_test) - 47, 24):\n",
    "    window = df_test['Price'].iloc[i:i+48].values\n",
    "    if len(window) == 48:\n",
    "        real_values.append(window)\n",
    "        forecast_index.append(df_test.index[i])\n",
    "\n",
    "real_values = pd.DataFrame(real_values, index=forecast_index, columns=['h' + str(k) for k in range(48)])\n",
    "forecast_dates = forecast.index\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# STEP 1: FORECAST HOURS 0–23 (DAY +1)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Initialize model and forecast DataFrame\n",
    "model = LEAR(calibration_window=calibration_window)\n",
    "forecast_d1 = pd.DataFrame(index=forecast_dates, columns=[f'h{k}' for k in range(24)])\n",
    "\n",
    "for date in forecast_dates:\n",
    "    # Prepare input: combine train and up-to-date test data\n",
    "    data_available = pd.concat([df_train, df_test.loc[:date + pd.Timedelta(hours=23)]])\n",
    "    \n",
    "    # Mask the next 24h (to be predicted)\n",
    "    data_available.loc[date:date + pd.Timedelta(hours=23), 'Price'] = np.NaN\n",
    "\n",
    "    # Forecast next 24 hours using LEAR\n",
    "    Yp_d1 = model.recalibrate_and_forecast_next_day(df=data_available,\n",
    "                                                    next_day_date=date,\n",
    "                                                    calibration_window=calibration_window)\n",
    "    forecast_d1.loc[date] = Yp_d1.flatten()\n",
    "\n",
    "    # Save interim results\n",
    "    forecast_d1.to_csv(path_recalibration_folder + '/forecast_d1.csv')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# STEP 2: FORECAST HOURS 24–47 (DAY +2) USING STEP 1 RESULTS\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "forecast_d1 = pd.read_csv(path_recalibration_folder + '/forecast_d1.csv', index_col=0, parse_dates=True)\n",
    "forecast_d2 = pd.DataFrame(index=forecast_dates, columns=[f'h{k}' for k in range(24)])\n",
    "forecast_48h = pd.DataFrame(index=forecast_dates, columns=[f'h{k}' for k in range(48)])\n",
    "\n",
    "for date in forecast_dates:\n",
    "    data_available = pd.concat([df_train, df_test.loc[:date + pd.Timedelta(hours=47)]])\n",
    "    d1_index = pd.date_range(date, date + pd.Timedelta(hours=23), freq='h')\n",
    "\n",
    "    # Replace day +1 prices with step-1 forecasts\n",
    "    data_available.loc[d1_index, 'Price'] = forecast_d1.loc[date].values\n",
    "\n",
    "    # Extend historical window to ensure context for D+2\n",
    "    df_test_expanded = data_available.loc[date - pd.Timedelta(days=10):date + pd.Timedelta(days=2)]\n",
    "\n",
    "    try:\n",
    "        _, _, X_d2 = model._build_and_split_XYs(df_train=data_available,\n",
    "                                                df_test=df_test_expanded,\n",
    "                                                date_test=date + pd.Timedelta(days=1))\n",
    "        Yp_d2 = model.predict(X_d2)\n",
    "        forecast_d2.loc[date] = Yp_d2.flatten()\n",
    "\n",
    "        # Concatenate 48h forecast\n",
    "        forecast_48h.loc[date] = np.concatenate([forecast_d1.loc[date].values, Yp_d2.flatten()])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {date} due to: {e}\")\n",
    "        continue\n",
    "\n",
    "forecast_48h.to_csv(path_recalibration_folder + '/forecast_48h.csv')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# FORECAST TO LONG FORMAT FOR ERROR ANALYSIS\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "df_long = forecast_48h.copy()\n",
    "df_long.index.name = 'forecast_issue_time'  # Ensure index has the correct name\n",
    "df_long = df_long.reset_index()  # Now this becomes a column\n",
    "\n",
    "records = []\n",
    "for _, row in df_long.iterrows():\n",
    "    issue_time = row['forecast_issue_time']\n",
    "    for h in range(48):\n",
    "        records.append({\n",
    "            'forecast_issue_time': issue_time,\n",
    "            'target_time': issue_time + pd.Timedelta(hours=h),\n",
    "            'lead_time_hr': h,\n",
    "            'forecast_price': row[f'h{h}']\n",
    "        })\n",
    "\n",
    "df_leadtime = pd.DataFrame(records)\n",
    "\n",
    "# Add actual prices to compute errors\n",
    "actual_prices = df_test['Price'].copy().reset_index()\n",
    "actual_prices.rename(columns={'Date': 'target_time', 'Price': 'actual_price'}, inplace=True)\n",
    "df_leadtime = df_leadtime.merge(actual_prices, on='target_time', how='left')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# ERROR METRICS\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Clean up\n",
    "df_leadtime['forecast_price'] = pd.to_numeric(df_leadtime['forecast_price'], errors='coerce')\n",
    "df_leadtime['abs_error'] = (df_leadtime['forecast_price'] - df_leadtime['actual_price']).abs()\n",
    "df_leadtime['sMAPE'] = 200 * df_leadtime['abs_error'] / (\n",
    "    df_leadtime['forecast_price'].abs() + df_leadtime['actual_price'].abs()\n",
    ")\n",
    "\n",
    "\n",
    "# Average error by forecast lead time\n",
    "error_by_lead = df_leadtime.groupby('lead_time_hr')[['abs_error', 'sMAPE']].mean()\n",
    "print(error_by_lead)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# PROBABILISTIC FORECASTING (QUANTILES & SCORING)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Compute rolling residuals\n",
    "df_leadtime['residual'] = df_leadtime['actual_price'] - df_leadtime['forecast_price']\n",
    "start_prob_date = pd.Timestamp(\"2018-03-01\")\n",
    "rolling_window_days = 60\n",
    "quantile_records = []\n",
    "forecast_dates = sorted(df_leadtime['forecast_issue_time'].unique())\n",
    "\n",
    "# Rolling quantile computation per lead time\n",
    "for current_date in forecast_dates:\n",
    "    if current_date < start_prob_date:\n",
    "        continue\n",
    "    window_start = current_date - pd.Timedelta(days=rolling_window_days)\n",
    "    residuals_window = df_leadtime[\n",
    "        (df_leadtime['forecast_issue_time'] >= window_start) &\n",
    "        (df_leadtime['forecast_issue_time'] < current_date)\n",
    "    ]\n",
    "\n",
    "    quantiles = (\n",
    "        residuals_window\n",
    "        .groupby('lead_time_hr')['residual']\n",
    "        .apply(lambda x: x.quantile([0.1, 0.9]) if len(x) >= 30 else pd.Series([np.nan, np.nan], index=[0.1, 0.9]))\n",
    "        .unstack()\n",
    "    )\n",
    "    quantiles.columns = ['q10', 'q90']\n",
    "\n",
    "    current_forecast = df_leadtime[df_leadtime['forecast_issue_time'] == current_date].copy()\n",
    "    current_with_quantiles = current_forecast.merge(quantiles, on='lead_time_hr', how='left')\n",
    "    current_with_quantiles['P10'] = current_with_quantiles['forecast_price'] + current_with_quantiles['q10']\n",
    "    current_with_quantiles['P90'] = current_with_quantiles['forecast_price'] + current_with_quantiles['q90']\n",
    "    quantile_records.append(current_with_quantiles)\n",
    "\n",
    "df_prob_forecast = pd.concat(quantile_records, ignore_index=True)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# INTERVAL SCORE & PINBALL LOSS\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def interval_score(upper, lower, actual, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Compute the interval score for prediction intervals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    upper : pd.Series\n",
    "        Upper prediction bound.\n",
    "    lower : pd.Series\n",
    "        Lower prediction bound.\n",
    "    actual : pd.Series\n",
    "        True observed values.\n",
    "    alpha : float\n",
    "        Confidence level (e.g. 0.2 for 80% interval).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Interval score per observation.\n",
    "    \"\"\"\n",
    "    width = upper - lower\n",
    "    below = (lower - actual) * (actual < lower)\n",
    "    above = (actual - upper) * (actual > upper)\n",
    "    penalty = (2 / alpha) * (below + above)\n",
    "    return width + penalty\n",
    "\n",
    "df_prob_forecast['IS_80'] = interval_score(\n",
    "    df_prob_forecast['P90'],\n",
    "    df_prob_forecast['P10'],\n",
    "    df_prob_forecast['actual_price'],\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "def pinball_loss(q, y, tau):\n",
    "    \"\"\"\n",
    "    Compute the pinball loss for quantile forecasts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : pd.Series\n",
    "        Forecasted quantile value.\n",
    "    y : pd.Series\n",
    "        Actual observed value.\n",
    "    tau : float\n",
    "        Quantile level (e.g. 0.1 or 0.9)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Pinball loss value.\n",
    "    \"\"\"\n",
    "    return (tau - (y < q)) * (y - q)\n",
    "\n",
    "df_prob_forecast['PL_P10'] = df_prob_forecast.apply(\n",
    "    lambda row: pinball_loss(row['P10'], row['actual_price'], 0.1), axis=1\n",
    ")\n",
    "df_prob_forecast['PL_P90'] = df_prob_forecast.apply(\n",
    "    lambda row: pinball_loss(row['P90'], row['actual_price'], 0.9), axis=1\n",
    ")\n",
    "\n",
    "# Print average scores\n",
    "print( \"Average Interval Score (80%):\", df_prob_forecast['IS_80'].mean())\n",
    "print(\"Average Pinball Loss P10:\", df_prob_forecast['PL_P10'].mean())\n",
    "print(\"Average Pinball Loss P90:\", df_prob_forecast['PL_P90'].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epftoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
